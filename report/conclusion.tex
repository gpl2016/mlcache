\section{Conclusion}

Our prototype MLCache has proven to be on par with the Linux implementation for
read-intensive workflows such as the the \textbf{pgbench} benchmark. This shows
great promise, since a number of improvements are possible and yet, we had
comparable results when compared to the standard Linux LRU implementation. For
other results, like the \textbf{cscope} benchmark, we are still in the process
of improving the implementation so, even for these cases, the performance gap
will diminish as our design matures. Overall, with a very simple design, we
have shown that an adaptive approach to caching can be beneficial to
potentially different kinds of applications. This is only the first step;
further work is needed in order to use optimized data structures for our
eviction policy, which could bring even greater performance gains.
Most importantly, we believe that machine learning techniques
can be leveraged in order to provide increased performance to existing,
unchanged applications.
