\section{Introduction}

Application-controlled caching has been proposed as an alternative to global caching policies that might not be appropriate for different types of applications, each with different caching needs. In particular, monolithic systems like Linux lack the flexibility to meet applications' requirements. These approaches often show beneficial results, especially when incorporated with different techniques such as disk scheduling, and prefetching \cite{Cao:1996}. The main issue, however, is that application developers would suffer if they are not keen enough to be able to provide a good policy for their applications. This problem becomes especially hard when taking into account the interplay between several concurrent processes, which are constantly competing for resources. Additionally, these policies should be adaptable to different workloads, possibly changing on the fly. Thus, this design is not practical. A potential solution to this complex problem is the use of machine learning, through the use of unsupervised techniques, or supervised techniques that require minimal input from a developer. We believe that this approach should provide similar enhancements to those previously seen from application-controlled caching policies, while being substantially easier to maintain, and ideally hiding the complexities from the developer by pushing the work to the kernel. We build a prototype on top of the Linux LRU implementation, keeping track of scores for pages in the cache, updating them at each step, either rewarding or penalizing as we see fit.
